"""
Heuristics for detecting packed PE files.
When main is invoked, all functions starting with 'check_' are run on the requested file(s).
"""

# standard imports
import argparse
import collections
import math
import os
import re
import sys

# dependencies
import pefile
import yara

##################################################
# GLOBALS
##################################################

gVerbose = False
gVerboseMaxLines = 10
gCheckStats = collections.Counter()
gFileStats = collections.Counter()
gFileCount = 0
gStringStats = collections.Counter()
gCompiledRules = None

##################################################
# CONSTANTS
##################################################

MINIMUM_NUM_SECTIONS = 3  # low number of sections may suggest packer

MINIMUM_NUM_IMPORTS = 5   # few imports may suggest packer

MINIMUM_NUM_LIBRARIES = 3  # packed files usually don't need many libraries (dlls)

SUSPICIOUS_SECTION_NAMES = [  # common packer section names
    'upx',
    'pack',
    'nsp',
    'yc',
    '.yp',
    'mew',
    '.pcpec',
    '.stone',
    'weijunli',
    '.teraphy',
    'rr0',
    'sqd',
]

TYPICAL_SECTION_FLAGS = {  # typical RWE flags
    '.bss': 'RW-',
    '.data': 'RW-',
    '.edata': 'R--',
    '.idata': 'R?-',
    '.rdata': 'R--',
    '.reloc': 'R--',
    '.rsrc': 'R?-',
    '.orpc': 'R-E',
    '.text': 'R-E',
    '.didat': 'RW-',
    '.imrsiv': 'RW-',
    '.instanc': 'RW-',
    '.pdata': 'R--',
    '.crt': 'RW-',
    '.gnu_deb': 'R--',
    '.rossym': 'R--',
    '.tls': 'RW-',
}

PACKER_IMPORTS = [   # imports that might be useful for unpacking
    'LoadLibrary',
    'GetProcAddress',
    'VirtualProtect',
    'VirtualAlloc',
    'GetModuleHandle',
]

MIN_STR_LEN = 8  # only count strings that are at least this long
MIN_STR_A_COUNT = 40  # suspicious to have fewer than this many ascii strings
MIN_STR_W_COUNT = 10  # suspicious to have fewer than this many wide (utf16) strings

ENTROPY_THRESHOLD = 6.9  # high entropy sections may be packed

EXECUTABLE_THRESHOLD = 0.2  # low executable fraction of binary may indicate packer

##################################################
# Utility functions
##################################################


def get_section_name(section):
    """get (and clean) name of section"""
    return section.Name.decode('ascii', errors='backslashreplace').lower().rstrip('\x00')


def get_section_flags(section):
    """return RWE flags"""
    flags = ''
    if section.Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_READ']:
        flags += 'R'
    else:
        flags += '-'
    if section.Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_WRITE']:
        flags += 'W'
    else:
        flags += '-'
    if section.Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_EXECUTE']:
        flags += 'E'
    else:
        flags += '-'
    return flags


def get_section_expected_flags(pe, section_name):
    """Return flags typically associated with sections that have this name, or None"""
    if section_name in TYPICAL_SECTION_FLAGS:
        return TYPICAL_SECTION_FLAGS[section_name]
    return None


def flags_are_unusual(actual_flags, expected_flags):
    """return True if flags do not match"""
    FLAG_LEN = 3
    assert len(actual_flags) == FLAG_LEN   # expect something like 'RWE'
    assert len(expected_flags) == FLAG_LEN  # expect something like 'RWE'
    for i in range(FLAG_LEN):
        if expected_flags[i] == '?':
            # this flag can be anything, we don't have an expected value
            continue
        elif expected_flags[i] != actual_flags[i]:
            # flag does not match expected!
            return True
    return False  # we did not find any unusual flags


def get_section_summary(pe, include_entropy=True, sep=' '):
    """return string summarizing sections (names, flags, sizes)"""
    summary = ''
    for section in pe.sections:
        name = get_section_name(section)
        flags = get_section_flags(section)
        raw_size = section.SizeOfRawData
        virt_size = section.Misc_VirtualSize
        summary_list = [
            ('"%s"' % name).ljust(8, ' '),
            flags,
            'raw='+hex(raw_size).ljust(10, ' '),
            'virt='+hex(virt_size).ljust(10, ' '),
        ]
        if include_entropy:
            summary_list.append('entropy=%0.1f' % section.get_entropy())
        summary += sep.join(summary_list)+'; '
    return summary


def is_resource_only(pe):
    """return True if PE looks like it is just resources and not executable"""

    # we expect null entry point
    if not hasattr(pe, 'OPTIONAL_HEADER'):
        return False
    if pe.get_section_by_rva(pe.OPTIONAL_HEADER.AddressOfEntryPoint) is None:
        if pe.OPTIONAL_HEADER.AddressOfEntryPoint != 0:
            return False

    # we expect two sections
    if len(pe.sections) != 2:
        return False

    # we expect first section to be ".rsrc"
    if get_section_name(pe.sections[0]) != ".rsrc":
        return False

    # we expect second section to be ".reloc"
    if get_section_name(pe.sections[1]) != ".reloc":
        return False

    # we expect sections to be non-executable
    if pe.sections[0].Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_EXECUTE']:
        return False
    if pe.sections[1].Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_EXECUTE']:
        return False

    # we passed all our tests, this looks like resource only
    return True


def get_ascii_matches(pe):
    return re.finditer(b'[\x20-\x7e]{%d,}' % MIN_STR_LEN, pe.__data__)


def get_ascii(pe):
    """return generator to get ascii strings from PE"""
    for s in get_ascii_matches(pe):
        yield s.group(0).decode('ascii', errors='backslashreplace')


def get_utf16_matches(pe):
    return re.finditer(b'([\x20-\x7e]\\x00){%d,}' % MIN_STR_LEN, pe.__data__)


def run_yara(pe):

    # compile all rules
    global gCompiledRules
    if gCompiledRules is None:
        gCompiledRules = []
        rules_dir = os.path.join(os.path.dirname(__file__), 'rules')
        for file in os.listdir(rules_dir):
            if file.endswith('.yar'):
                file_path = os.path.join(rules_dir, file)
                gCompiledRules.append(yara.compile(file_path))

    matches = []
    for rules in gCompiledRules:
        matches.extend(rules.match(data=bytes(pe.__data__)))
    return matches


##################################################
# Check functions
##################################################


def check_expected_section_flags(pe):
    """check RWE flags of sections with common names"""
    sections_with_unexpected_flags = []
    for section in pe.sections:
        name = get_section_name(section)
        expected_flags = get_section_expected_flags(pe, name)
        if expected_flags is not None:
            actual_flags = get_section_flags(section)
            if flags_are_unusual(actual_flags, expected_flags):
                sections_with_unexpected_flags.append('"%s" is %s (typically %s)'%(name, actual_flags, expected_flags))
    if sections_with_unexpected_flags:
        return 'Unusual section flags: '+', '.join(sections_with_unexpected_flags)


def check_section_count(pe):
    if len(pe.sections) < MINIMUM_NUM_SECTIONS:
        if not is_resource_only(pe):
            return 'Less than %d sections (and not resource only).' % MINIMUM_NUM_SECTIONS
    # TODO upper threshold too?
    return None


def check_section_names(pe):
    suspicious_section_names = []
    for section in pe.sections:
        name = get_section_name(section)
        suspicious = False
        for indicator in SUSPICIOUS_SECTION_NAMES:
            if indicator in name:
                suspicious = True
        if name == '':
            suspicious = True
        if '\x00' in name:
            suspicious = True
        if suspicious:
            suspicious_section_names.append(name)
    if suspicious_section_names:
        return 'Suspicious section names: '+str(suspicious_section_names)
    return None


def check_first_section_raw_size(pe):
    if pe.sections:
        if pe.sections[0].SizeOfRawData == 0:
            return 'First section has a raw (on disk) size of zero.'
    return None


def check_last_section_executable(pe):
    if len(pe.sections) > 1:
        if pe.sections[-1].Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_EXECUTE']:
            return 'Last section is executable.'
    return None


def check_first_section_writable(pe):
    if len(pe.sections) > 0:
        if pe.sections[0].Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_WRITE']:
            return 'First section is writable.'
    return None


def check_executable_and_zero_size(pe):
    exe_and_zero_sections = []
    for section in pe.sections:
        if section.SizeOfRawData == 0:
            if section.Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_EXECUTE']:
                exe_and_zero_sections.append(get_section_name(section))
    if exe_and_zero_sections:
        return 'Executable sections with a raw (on disk) size of zero: '+str(exe_and_zero_sections)
    return None


def check_executable_and_writable(pe):
    exe_and_writable_sections = []
    for section in pe.sections:
        if section.Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_EXECUTE']:
            if section.Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_WRITE']:
                exe_and_writable_sections.append(get_section_name(section))
    if exe_and_writable_sections:
        return 'Executable and writable sections: '+str(exe_and_writable_sections)
    return None


def check_virtual_greater_than_physical(pe):
    page_size = 0x1000  # should we use section alignment specified in file instead of harding code this?
    expanding_sections = []
    for section in pe.sections:
        raw_size = section.SizeOfRawData
        if raw_size == 0:
            continue  # we would expect this section to get bigger
        if get_section_name(section) == '.data':
            continue  # more common for .data to be bigger in memory
        virt_size = section.Misc_VirtualSize
        if virt_size > page_size * math.ceil(raw_size / page_size):
            summary = '"%s" raw=%s virt=%s' %(get_section_name(section), hex(raw_size), hex(virt_size))
            expanding_sections.append(summary)
    if expanding_sections:
        return 'Section is bigger in memory than on disk: '+', '.join(expanding_sections)
    return None


def check_entropy(pe):
    high_entropy_sections = []
    for section in pe.sections:
        entropy = section.get_entropy()
        if entropy >= ENTROPY_THRESHOLD:
            summary = '"%s" %0.1f' % (get_section_name(section), entropy)
            high_entropy_sections.append(summary)
    if high_entropy_sections:
        return 'High entropy sections: '+', '.join(high_entropy_sections)
    return None


def skip_check_fraction_executable(pe):
    """skip check, just as many false positives as true positives"""
    exec_size = 0
    total_size = 0
    for section in pe.sections:
        total_size += section.SizeOfRawData
        if section.Characteristics & pefile.SECTION_CHARACTERISTICS['IMAGE_SCN_MEM_EXECUTE']:
            exec_size += section.SizeOfRawData
    if total_size > 0:
        if exec_size > 0:
            if (exec_size / total_size) < EXECUTABLE_THRESHOLD:
                return 'Executable code is a small fraction of total.  (%0.1f%%)  <weak indicator>' % (100.0 * exec_size / total_size)
    return None


def check_entry_not_in_section(pe):
    if not hasattr(pe, 'OPTIONAL_HEADER'):
        return
    if pe.get_section_by_rva(pe.OPTIONAL_HEADER.AddressOfEntryPoint) is None:
        if pe.OPTIONAL_HEADER.AddressOfEntryPoint != 0:
            return 'Entry point is non-null and not in any section.  (%s)' % hex(pe.OPTIONAL_HEADER.AddressOfEntryPoint)
    return None


def check_entry_in_last_section(pe):
    if len(pe.sections) < 2:
        return None
    entry_section = pe.get_section_by_rva(pe.OPTIONAL_HEADER.AddressOfEntryPoint)
    if entry_section == pe.sections[-1]:
        return 'Entry point is in last section.'
    return None


def check_import_count(pe):
    """Number of imported functions can be a weak indicator"""

    if not hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
        if is_resource_only(pe):
            return None
        else:
            return 'No import table found (and not resource only).  <weak indicator>'

    cnt = 0
    for d in pe.DIRECTORY_ENTRY_IMPORT:
        cnt += len(d.imports)

    if cnt < MINIMUM_NUM_IMPORTS:
        return 'Very few imports. (%d)  <weak indicator>' % cnt
    return None


def check_import__library_count(pe):
    """Using few dlls can be a weak indicator"""

    if not hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
        return None

    cnt = len(pe.DIRECTORY_ENTRY_IMPORT)

    if gVerbose:
        print('Libraries[%d]:' % cnt)
        for d in pe.DIRECTORY_ENTRY_IMPORT:
            module = d.dll.lower().decode('ascii', errors='backslashreplace')
            print('    '+module)

    if cnt < MINIMUM_NUM_LIBRARIES:
        return 'Very few libraries.  (%d)  <weak indicator>' % cnt
    return None


def check_import_functions(pe):

    if not hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
        return None

    num_imports = 0
    for d in pe.DIRECTORY_ENTRY_IMPORT:
        num_imports += len(d.imports)

    found_loadlibrary = False
    suspicious_imports = []
    if gVerbose:
        print('Imports[%d]:' % num_imports)
        print_count = 0
    for d in pe.DIRECTORY_ENTRY_IMPORT:
        module = d.dll
        for i in d.imports:
            try:
                import_name = (module.lower() + b'.' + i.name).decode('ascii', errors='backslashreplace')
            except TypeError:
                import_name = (module.lower() + b'[ordinal %d]' % i.ordinal).decode('ascii', errors='backslashreplace')
            if gVerbose:
                if print_count < gVerboseMaxLines:
                    print('    '+import_name)
                    print_count += 1
            suspicious = False
            if 'LoadLibrary' in import_name:
                found_loadlibrary = True
            for n in PACKER_IMPORTS:
                if n in import_name:
                    suspicious = True
            if suspicious:
                suspicious_imports.append(import_name)
    if gVerbose:
        if print_count >= gVerboseMaxLines:
            print('    ...')

    if found_loadlibrary:
        if suspicious_imports and (num_imports < 3*MINIMUM_NUM_IMPORTS):
            return 'Imports that might be used for unpacking: '+str(suspicious_imports)
    return None


def check_strings_ascii(pe):
    typical_first_str = '!This program cannot be run in DOS mode.'
    typical_strs = ['.dll', '.pdb', '.text', '.rdata', '.rsrc', 'uvwatauavawh', 'h3e h3e', 'watauavawh', 'atavawh']
    search_window = 10

    first_str = ''
    strs = ''
    cnt = 0
    for s in get_ascii(pe):#
        if cnt == 0:
            first_str = s
        else:
            strs += s.lower() + ';'
        cnt += 1
        if cnt >= search_window:
            break
    if first_str == 'kernel32.dll':
        return 'Expecting first string to be "%s" but found "%s"  This may be packed with MEW10.' % (typical_first_str, first_str)
    if first_str == 'MZkernel32.dll':
        return 'Expecting first string to be "%s" but found "%s"  This may be packed with MEW.' % (typical_first_str, first_str)
    if first_str == 'This program must be run under Win32':
        return 'Expecting first string to be "%s" but found "%s"  This may be packed with PEPACK.' % (typical_first_str, first_str)
    if first_str == 'MZKERNEL32.DLL':
        return 'Expecting first string to be "%s" but found "%s"  This may be packed with Upack037.' % (typical_first_str, first_str)
    if first_str == '!Windows Program':
        return 'Expecting first string to be "%s" but found "%s"  This may be packed with FSG1.' % (typical_first_str, first_str)
    if first_str == 'KERNEL32.dll':
        return 'Expecting first string to be "%s" but found "%s"  This may be packed with FSG.' % (typical_first_str, first_str)
    if 'nspack' in first_str:
        return 'Expecting first string to be "%s" but found "%s"  This may be packed with nspack.' % (typical_first_str, first_str)

    if first_str != typical_first_str:
        return 'Expecting first string to be "%s" but found "%s"' % (typical_first_str, first_str)
    if not any([s in strs for s in typical_strs]):
        return 'Did not find any of %s in the first %d strings.  <weak indicator>' % (str(typical_strs), search_window)
    return None


def check_string_ascii_count(pe):
    """Having few ascii strings is a weak indicator"""
    num_strs = len(list(get_ascii_matches(pe)))
    if gVerbose:
        max_line_len = 80
        print('Strings[%d]:' % num_strs)
        print_count = 0
        for s in get_ascii(pe):
            print_count += 1
            if len(s) > max_line_len-4:
                s = s[0:max_line_len-7]+'...'
            print('    ' + s)
            gStringStats[s] += 1
            if print_count >= gVerboseMaxLines:
                break
        if num_strs > gVerboseMaxLines:
            print('    ...')
    if num_strs < MIN_STR_A_COUNT:
        return 'Very few ASCII strings found (%d).  <weak indicator>' % num_strs
    return None


def check_string_utf16_count(pe):
    num_strs = len(list(get_utf16_matches(pe)))
    if num_strs < MIN_STR_W_COUNT:
        return 'Very few UTF16 strings found (%d).' % num_strs
    return None


##################################################
# All Check functions list
##################################################

locs = locals()
CHECKS = [locs[chk_fcn] for chk_fcn in dir() if chk_fcn.startswith('check_')]

##################################################
# Main
##################################################

# TODO test python 2.7
# TODO benign files from win10


def analyze(filepath):
    """
    run all check functions on file and return list packing indications.
    Raises OSError, pefile.PEFormatError
    """
    pe = pefile.PE(filepath)

    if gVerbose:
        print('Sections[%d]:' % len(pe.sections))
        for section_summary in get_section_summary(pe).split(';'):
            section_summary = section_summary.strip()
            if section_summary:
                print('    ' + section_summary)

    # run checks on PE
    packed_indicators = []
    for check in CHECKS:
        indicator = check(pe)
        if indicator:
            gCheckStats[check] += 1
            packed_indicators.append(indicator)

    sig_matches = None  # run_yara(pe)

    return packed_indicators, sig_matches


def main(fpath):
    """
    takes a file or folder path and analyze each file.
    prints any indications of packing found.
    """
    global gFileCount

    # loop over directory
    if os.path.isdir(fpath):
        for p in os.listdir(fpath):
            main(os.path.join(fpath, p))
        return

    # run checks on PE
    print('')
    print(fpath)
    try:
        packed_indicators, sig_matches = analyze(fpath)
    except pefile.PEFormatError as e:
        print('Unable to analyze file: '+str(e))
        return
    except OSError as e:
        print('Unable to analyze file: '+str(e))
        return
    gFileCount += 1

    # print results
    if not packed_indicators:
        print('No indicators of packing were found.')
    else:
        print('%d/%d possible packing indicators:' % (len(packed_indicators), len(CHECKS)))
        for indicator in packed_indicators:
            print('    %s' % indicator)
        gFileStats[len(packed_indicators)] += 1
    if sig_matches:
        print('Signature Matches: ', sig_matches)


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('path', help='PE file or directory of PE files')
    parser.add_argument('-v', '--verbose', action='store_true')
    parser.add_argument('-n', '--num-lines', default=gVerboseMaxLines, type=int, help='number of strings/imports to print in verbose mode')
    args = parser.parse_args()

    gVerbose = args.verbose
    gVerboseMaxLines = args.num_lines
    main(args.path)

    if gVerbose:
        if gCheckStats:
            if os.path.isdir(args.path):
                print('')
                print('Indicator summary:')
                for k,v in gCheckStats.most_common():
                    print('    ', v, k.__name__)
        if gFileStats:
            print('')
            print('File Summary:')
            print('    %d files scanned.' % gFileCount)
            filestats = gFileStats.most_common()
            filestats.sort(reverse=True)
            for indicators,files in filestats:
                msg = '    %d files with %d indicators' % (files, indicators)
                msg = msg.replace(' 1 files', ' 1 file')
                msg = msg.replace(' 1 indicators', ' 1 indicator')
                print(msg)
        # if gStringStats:
        #     print('')
        #     print('Early string summary:')
        #     for k,v in gStringStats.most_common():
        #         print('    ', v, k)
